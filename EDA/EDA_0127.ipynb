{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1yHcy75mMuKJ0pFjuhzRq_522IyK-JW4o","authorship_tag":"ABX9TyPjDPnrz3ExhPlTR8ZTIRRa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout\n","from tensorflow.keras import Sequential"],"metadata":{"id":"w0GEvddJLEO4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train      = pd.read_csv(\"/content/drive/MyDrive/github_commit/sooktat_DL_project/dataset/train_data.csv\")\n","test       = pd.read_csv(\"/content/drive/MyDrive/github_commit/sooktat_DL_project/dataset/test_data.csv\")\n","submission = pd.read_csv(\"/content/drive/MyDrive/github_commit/sooktat_DL_project/dataset/sample_submission.csv\")\n","topic_dict = pd.read_csv(\"/content/drive/MyDrive/github_commit/sooktat_DL_project/dataset/topic_dict.csv\")"],"metadata":{"id":"tZ556vVRLLQY","executionInfo":{"status":"ok","timestamp":1674829353902,"user_tz":-540,"elapsed":2597,"user":{"displayName":"정재원","userId":"04462291140652462847"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# BASELINE code 에서의 전처리 코드\n","## 1) Simple_Dense_Layer_Model"],"metadata":{"id":"flbeLdHUGHh2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"jG3WhWBBFS7D"},"outputs":[],"source":["# ------ 코드분석 (1) -------\n","def clean_text(sent):\n","  sent_clean = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \" \", sent)\n","  return sent_clean\n","\n","# ------ 코드분석 (2) -------\n","train[\"cleaned_title\"] = train[\"title\"].apply(lambda x : clean_text(x))\n","test[\"cleaned_title\"]  = test[\"title\"].apply(lambda x : clean_text(x))\n","\n","train_text = train[\"cleaned_title\"].tolist() # .tolist() : series 형식으로 된 데이터를 list로\n","test_text = test[\"cleaned_title\"].tolist()\n","train_label = np.asarray(train.topic_idx) # np.asarray() : series 형식으로 된 데이터를 array로\n","\n","# ------ 코드분석 (3) -------\n","tfidf = TfidfVectorizer(analyzer='word', sublinear_tf=True, ngram_range=(1, 2), max_features=150000, binary=False)\n","\n","tfidf.fit(train_text)\n","\n","train_tf_text = tfidf.transform(train_text).astype('float32')\n","test_tf_text  = tfidf.transform(test_text).astype('float32')"]},{"cell_type":"markdown","source":["### 코드분석 (1)\n","\n","\n","```\n","re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \" \", sent)\n","```\n","<br/>\n","\n","1.   정규표현식\n","\n","\n","|제목|내용|\n","|:---:|---|\n","| [^xy] |not 을 표현하며  x 및 y 를 제외한 문자를 의미한다.|\n","|[x-z]|\trange를 표현하며 x ~ z 사이의 문자를 의미한다. |\n","|\\\\s|space 를 표현하며 공백 문자를 의미한다. |\n","\n","<br/>\n","\n","[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s] 의미   \n",": [ '가'부터 '힣'까지 (모음자음병합어) + 'ㄱ'부터 'ㅎ'까지 (자음) + 'ㅏ'부터 'ㅣ'까지 (모음) + 공백(blank) ] 에 해당되는 문자로 시작하는 문자열을 제외한 모든 문자열\n","\n","<br/>\n","\n","2. re.sub()\n","\n","re.sub（정규 표현식, 치환 문자, 대상 문자열）  \n",": 정규 표현식에 해당되는 문자들을 지정한 문자로 치환\n","\n","ex.\n","\n","```\n","import re  \n","\n","text = \"I like apble And abple\" \n","text_mod = re.sub('apble|abple',\"apple\",text) \n","\n","print (text_mod)\n","```\n","\n","<br/>\n","\n","즉, 상기 코드의 의미  \n",": sent라는 문자 데이터에서 / '가'부터 '힣'까지 (모음자음병합어) + 'ㄱ'부터 'ㅎ'까지 (자음) + 'ㅏ'부터 'ㅣ'까지 (모음) + 공백(blank) 에 해당되는 모든 문자로 시작되는 문자열들을 제외한 모든 문자열을 / 공백(blank)로 치환한다."],"metadata":{"id":"sMHA6LllGYfA"}},{"cell_type":"markdown","source":["### 코드분석 (2)\n","\n","\n","\n","```\n","train[\"cleaned_title\"] = train[\"title\"].apply(lambda x : clean_text(x))\n","test[\"cleaned_title\"]  = test[\"title\"].apply(lambda x : clean_text(x))\n","\n","train_text = train[\"cleaned_title\"].tolist() # .tolist() : series 형식으로 된 데이터를 list로\n","test_text = test[\"cleaned_title\"].tolist()\n","train_label = np.asarray(train.topic_idx) # np.asarray() : series 형식으로 된 데이터를 array로\n","```\n","\n"],"metadata":{"id":"oWhnbLZoSlTZ"}},{"cell_type":"code","source":["train['title']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZdyOCVuJK6sR","executionInfo":{"status":"ok","timestamp":1674805410700,"user_tz":-540,"elapsed":6,"user":{"displayName":"정재원","userId":"04462291140652462847"}},"outputId":"37976b43-8813-406f-86a2-76a7cddb3ecf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0                  인천→핀란드 항공기 결항…휴가철 여행객 분통\n","1            실리콘밸리 넘어서겠다…구글 15조원 들여 美전역 거점화\n","2            이란 외무 긴장완화 해결책은 미국이 경제전쟁 멈추는 것\n","3          NYT 클린턴 측근韓기업 특수관계 조명…공과 사 맞물려종합\n","4                 시진핑 트럼프에 중미 무역협상 조속 타결 희망\n","                        ...                \n","45649          KB금융 미국 IB 스티펠과 제휴…선진국 시장 공략\n","45650       1보 서울시교육청 신종코로나 확산에 개학 연기·휴업 검토\n","45651           게시판 키움증권 2020 키움 영웅전 실전투자대회\n","45652                     답변하는 배기동 국립중앙박물관장\n","45653    2020 한국인터넷기자상 시상식 내달 1일 개최…특별상 김성후\n","Name: title, Length: 45654, dtype: object"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["train['cleaned_title']\n","# 첫번째 줄의 '->' '...' 가 공백으로\n","# 네번째 줄의 'NYT', '韓', '...' 가 공백으로\n","# 문자 전처리가 잘 되었음."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VHOjqe4OLojo","executionInfo":{"status":"ok","timestamp":1674805424230,"user_tz":-540,"elapsed":321,"user":{"displayName":"정재원","userId":"04462291140652462847"}},"outputId":"5245edbf-20eb-4935-eb97-7f22094133fc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0                  인천 핀란드 항공기 결항 휴가철 여행객 분통\n","1            실리콘밸리 넘어서겠다 구글   조원 들여  전역 거점화\n","2            이란 외무 긴장완화 해결책은 미국이 경제전쟁 멈추는 것\n","3              클린턴 측근 기업 특수관계 조명 공과 사 맞물려종합\n","4                 시진핑 트럼프에 중미 무역협상 조속 타결 희망\n","                        ...                \n","45649            금융 미국    스티펠과 제휴 선진국 시장 공략\n","45650        보 서울시교육청 신종코로나 확산에 개학 연기 휴업 검토\n","45651           게시판 키움증권      키움 영웅전 실전투자대회\n","45652                     답변하는 배기동 국립중앙박물관장\n","45653         한국인터넷기자상 시상식 내달  일 개최 특별상 김성후\n","Name: cleaned_title, Length: 45654, dtype: object"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["train_text # list로 저장됨"],"metadata":{"id":"65zAWpM5MGPq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.topic_idx # array로 저장됨"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CWaJgh0iMdZd","executionInfo":{"status":"ok","timestamp":1674805631776,"user_tz":-540,"elapsed":3,"user":{"displayName":"정재원","userId":"04462291140652462847"}},"outputId":"e1cb64e4-4dc3-40e9-ce8d-a526ba47250c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0        4\n","1        4\n","2        4\n","3        4\n","4        4\n","        ..\n","45649    1\n","45650    2\n","45651    1\n","45652    2\n","45653    2\n","Name: topic_idx, Length: 45654, dtype: int64"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["train_label"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SojaqZQsMTZ6","executionInfo":{"status":"ok","timestamp":1674805617218,"user_tz":-540,"elapsed":317,"user":{"displayName":"정재원","userId":"04462291140652462847"}},"outputId":"a3a18cd5-ecb2-41f0-b5d0-0aad216b52c8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([4, 4, 4, ..., 1, 2, 2])"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["### 코드 분석 (3)\n","\n","\n","\n","```\n","tfidf = TfidfVectorizer(analyzer='word', sublinear_tf=True, ngram_range=(1, 2), max_features=150000, binary=False)\n","\n","tfidf.fit(train_text)\n","\n","train_tf_text = tfidf.transform(train_text).astype('float32')\n","test_tf_text  = tfidf.transform(test_text).astype('float32')\n","```\n","\n","\n","</br>\n","\n","1. 개념 (참고 : https://mingchin.tistory.com/7)\n","\n","- **Tf (Term Frequency)** : 특정 단어가 한 문장에 출현하는 횟수  \n","- **Idf (Inverse of Documnet Frequency)** : df는 특정 단어가 몇 개의 문장에 출현하는지 횟수. 이에 역수를 취한 것이 Idf \n","- **Tfidf** :  tf 와 idf를 곱한 것  \n","\n","**TfidfVectorizer.fit(text)**를 통해 text가 가지고 있는 모든 단어를 BoW *(Bag of Words ; index로는 unique한 단어가 들어가고 value로 그 단어의 빈도가 들어간다)* 로 구성하고, 이 단어들에 대해 Tf-idf 값을 계산한 뒤 각 단어의 인덱스 위치에 Tf-idf 값이 들어간 벡터가 만들어진다.\n","\n","</br>\n","\n","2. 파라미터 (참고 : https://chan-lab.tistory.com/27)\n","\n","- **analyzer** : analyzer = 'word'라고 설정시, 학습의 단위를 단어로 설정\n","- **sublinear_tf** : sublinear_tf = True 로 설정하면 Tf 값을 'Tf -> 1 + ln(Tf)'로 변경하여 smoothing한다. 지나치게 큰 Tf 값을 갖는 이상치들이 존재할 때 효과적일 수 있다고 한다.\n","- **ngram_range** : n-gram이라는 것은 단어의 묶음을 말합니다.\n","이 단어의 묶음을 범위를 설정하는 것이 ngram_range 파라미터. ngram_range = (1, 2)라고 한다면, 단어의 묶음을 1개부터 2개까지 설정하라는 뜻.\n","- **max_features** : TF-IDF 벡터는 단어사전의 인덱스만큼 feature를 부여받습니다.  tf-idf vector의 최대 feature를 설정.\n","- **vacabulary** : 어떤 BoW로 벡터화를 진행할 지 직접 지정할 수 있다. (베이스라인 코드엔 없었지만 활용할 수 있을거같음)\n","\n","\n","\n","\n"],"metadata":{"id":"gaGLxlKwPT_n"}},{"cell_type":"code","source":["# 코드 참고 : https://mingchin.tistory.com/7\n","\n","# 각 단어와 맵핑된 인덱스 출력\n","list(tfidf.vocabulary_.items())[0:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CMRMFm4JT3OF","executionInfo":{"status":"ok","timestamp":1674807999565,"user_tz":-540,"elapsed":4,"user":{"displayName":"정재원","userId":"04462291140652462847"}},"outputId":"9de4b31d-209d-49b1-aa8c-de30aeb2caa1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('인천', 61024),\n"," ('핀란드', 128528),\n"," ('항공기', 135741),\n"," ('결항', 2010),\n"," ('휴가철', 148527),\n"," ('여행객', 29956),\n"," ('분통', 16937),\n"," ('인천 핀란드', 61107),\n"," ('핀란드 항공기', 128537),\n"," ('항공기 결항', 135742)]"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# train_text 로부터 각 단어의 빈도수(tfidf)를 기록\n","# (* RAM 문제로 train 데이터의 10개 문장에 대해서만 시행하였습니다.) \n","print(tfidf.fit_transform(train_text[0:10]).toarray())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_znDgCUGWDAi","executionInfo":{"status":"ok","timestamp":1674808864392,"user_tz":-540,"elapsed":413,"user":{"displayName":"정재원","userId":"04462291140652462847"}},"outputId":"adb02b7a-6c0d-4d09-845c-e953316e0a35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.        0.        0.        ... 0.2773501 0.2773501 0.       ]\n"," [0.        0.        0.2773501 ... 0.        0.        0.       ]\n"," [0.        0.        0.        ... 0.        0.        0.       ]\n"," ...\n"," [0.        0.        0.        ... 0.        0.        0.       ]\n"," [0.        0.        0.        ... 0.        0.        0.       ]\n"," [0.        0.        0.        ... 0.        0.        0.       ]]\n"]}]},{"cell_type":"code","source":["# 문서(문장) 간 유사도도 수치화\n","# (* RAM 문제로 train 데이터의 10개 문장에 대해서만 시행하였습니다.)\n","from sklearn.metrics.pairwise import linear_kernel\n","tfidf_matrix = tfidf.fit_transform(train_text[0:11])\n","cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n","cosine_sim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZgaYYolVXo6Y","executionInfo":{"status":"ok","timestamp":1674808746060,"user_tz":-540,"elapsed":361,"user":{"displayName":"정재원","userId":"04462291140652462847"}},"outputId":"ee1002e2-921d-42a0-8053-19da997b0417"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        ],\n","       [0.        , 1.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        ],\n","       [0.        , 0.        , 1.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        ],\n","       [0.        , 0.        , 0.        , 1.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 1.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        1.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 1.        , 0.        , 0.        , 0.        ,\n","        0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 1.        , 0.        , 0.04127242,\n","        0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 1.        , 0.        ,\n","        0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.04127242, 0.        , 1.        ,\n","        0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.        ,\n","        0.        , 0.        , 0.        , 0.        , 0.        ,\n","        1.        ]])"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["8번째 문장과 10번째 문장 간의 유사도 : 0.04127"],"metadata":{"id":"50MtB2OmZBuo"}},{"cell_type":"markdown","source":["## 2) LGBM"],"metadata":{"id":"krPivtRmZ6Pr"}},{"cell_type":"code","source":["!pip install konlpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m1SYmYKrmEHD","executionInfo":{"status":"ok","timestamp":1674829319415,"user_tz":-540,"elapsed":10179,"user":{"displayName":"정재원","userId":"04462291140652462847"}},"outputId":"fad991fc-57a9-468e-a01f-5026e4354cdc"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.21.6)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.2)\n","Collecting JPype1>=0.7.0\n","  Downloading JPype1-1.4.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.6/465.6 KB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n","Installing collected packages: JPype1, konlpy\n","Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import re\n","from konlpy.tag import Okt,Mecab\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score,f1_score\n","from lightgbm import LGBMClassifier"],"metadata":{"id":"xChmxWCOmqPk","executionInfo":{"status":"ok","timestamp":1674829322246,"user_tz":-540,"elapsed":2838,"user":{"displayName":"정재원","userId":"04462291140652462847"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# 형태소 분석기(Okt) 불러오기 \n","okt=Okt() \n","\n","# 조사, 어미, 구두점 제거\n","def func(text):\n","    clean = []\n","    for word in okt.pos(text, stem=True): #어간 추출\n","        if word[1] not in ['Josa', 'Eomi', 'Punctuation']: #조사, 어미, 구두점 제외 \n","            clean.append(word[0])\n","    \n","    \n","    return \" \".join(clean) \n","\n","train['title'] = train['title'].apply(lambda x : func(x))"],"metadata":{"id":"8gPqyI3imqil","executionInfo":{"status":"ok","timestamp":1674829462755,"user_tz":-540,"elapsed":72047,"user":{"displayName":"정재원","userId":"04462291140652462847"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# tf-idf를 이용한 벡터화\n","def split(text):\n","    tokens_ko = text.split()\n","    return tokens_ko\n","\n","tfidf_vect = TfidfVectorizer(tokenizer=split)\n","tfidf_vect.fit(train['title'])\n","tfidf_matrix_train = tfidf_vect.transform(train['title'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C9ROmioAnF_h","executionInfo":{"status":"ok","timestamp":1674829464313,"user_tz":-540,"elapsed":1566,"user":{"displayName":"정재원","userId":"04462291140652462847"}},"outputId":"102149b1-9885-4b3a-b5d3-46d49119da40"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# train/valid 데이터 셋 나누기.\n","def split_dataset(tfidf,df):\n","    X_data = tfidf\n","    y_data = df['topic_idx']\n","\n","    # stratify=y_data Stratified 기반 분할, train 데이터의 30%를 평가 데이터 셋으로 사용. (70% 데이터 학습에 사용)\n","    X_train, X_test, y_train, y_test = \\\n","    train_test_split(X_data, y_data, test_size=0.3, random_state=42, stratify=y_data)\n","\n","    \n","    return (X_train, X_test, y_train, y_test)\n","\n","X_train, X_test, y_train, y_test = split_dataset(tfidf_matrix_train,train)"],"metadata":{"id":"EK3objXlnHtr","executionInfo":{"status":"ok","timestamp":1674829464313,"user_tz":-540,"elapsed":7,"user":{"displayName":"정재원","userId":"04462291140652462847"}}},"execution_count":6,"outputs":[]}]}